{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "519807f4",
   "metadata": {},
   "source": [
    "Testet die Verlustfunktionen sowie ein Modell von variabler LÃ¤nge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c798db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "H = tf.constant([[1,2],\n",
    "                 [2,3],\n",
    "                 [3,4],\n",
    "                 [4,5],\n",
    "                 [5,6],\n",
    "                ], dtype=float)\n",
    "\n",
    "H = tf.reshape(H, (1,)+H.shape)\n",
    "\n",
    "# dot product score\n",
    "score = tf.matmul(H, H, transpose_b=True)\n",
    "\n",
    "# scale score\n",
    "dk = float(H.shape[-2])\n",
    "score /= tf.sqrt(dk)\n",
    "\n",
    "# softmax activation\n",
    "A = tf.keras.activations.softmax(score, axis=-1)\n",
    "\n",
    "# (deterministic) context vector\n",
    "c_det = tf.matmul(A,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f7eb382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 5), dtype=float32, numpy=\n",
       "array([[[3.4535166e-03, 1.3210785e-02, 5.0535418e-02, 1.9331384e-01,\n",
       "         7.3948640e-01],\n",
       "        [1.1653847e-04, 1.0903878e-03, 1.0202182e-02, 9.5456384e-02,\n",
       "         8.9313453e-01],\n",
       "        [3.4863342e-06, 7.9785830e-05, 1.8259232e-03, 4.1786812e-02,\n",
       "         9.5630401e-01],\n",
       "        [1.0003799e-07, 5.5997225e-06, 3.1344988e-04, 1.7545642e-02,\n",
       "         9.8213518e-01],\n",
       "        [2.8250795e-09, 3.8679164e-07, 5.2957017e-05, 7.2505325e-03,\n",
       "         9.9269617e-01]]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39b52f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 2), dtype=float32, numpy=\n",
       "array([[[4.6521688, 5.6521688],\n",
       "        [4.880402 , 5.880402 ],\n",
       "        [4.954308 , 5.954308 ],\n",
       "        [4.98181  , 5.98181  ],\n",
       "        [4.992643 , 5.9926424]]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b80419ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25 0.1 ]\n",
      " [0.75 0.25]\n",
      " [1.   0.  ]]\n",
      "[0.175 0.5   0.5  ]\n",
      "0.39166666666666666\n",
      "tf.Tensor(0.3916666507720947, shape=(), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[0.05       0.05       0.05       0.55000001]\n",
      " [0.5        0.         0.         1.5       ]\n",
      " [0.5        0.5        0.5        0.5       ]], shape=(3, 4), dtype=float64)\n",
      "(3, 4, 2)\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x1696628b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x1696628b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1696628b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[0.17500001 0.5        0.49999997]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "x1 = np.array([[[1, 1], [2, 1], [3,1], [4,1]],\n",
    "                 [[1.1, 1], [2.1, 1], [3.1,1], [4.1,1]],\n",
    "                 [[1.2, 1], [2.2, 1], [3.2,1], [4.2,1]],\n",
    "                ])\n",
    "x2 = np.array([[[1, 1.1], [2, 1.1], [3,1.1], [5,1.1]],\n",
    "                 [[1.1, 0], [2.1, 1], [3.1,1], [7.1,1]],\n",
    "                 [[2.2, 1], [3.2, 1], [4.2,1], [5.2,1]],\n",
    "                ])\n",
    "\n",
    "mse = np.mean(((x1-x2)**2)**0.5, axis=1)\n",
    "ansc = np.mean(mse, axis=-1)\n",
    "loss = np.mean(ansc)\n",
    "\n",
    "loss2 = tf.keras.losses.MeanAbsoluteError()(x1, x2)\n",
    "\n",
    "loss3 = tf.keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.NONE)(x1, x2)\n",
    "\n",
    "print(mse)\n",
    "print(ansc)\n",
    "print(loss)\n",
    "print(loss2)\n",
    "print(loss3)\n",
    "print(x1.shape)\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "class ReconstructionLossLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ReconstructionLossLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, x_hat =  inputs\n",
    "        \n",
    "        mse = tf.math.abs(tf.math.subtract(x, x_hat))\n",
    "        mse = tf.math.reduce_mean(mse, axis=(1,2))\n",
    "        \n",
    "        return mse\n",
    "    \n",
    "from tensorflow import keras\n",
    "\n",
    "inp1 = keras.Input(shape=x1.shape[1:])\n",
    "inp2 = keras.Input(shape=x1.shape[1:])\n",
    "out = ReconstructionLossLayer()([inp1, inp2])\n",
    "mod = keras.Model(inputs =[inp1,inp2], outputs=out)\n",
    "mod.compile()\n",
    "result = mod.predict([x1,x2])\n",
    "\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce8160e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mean_squared_error() got an unexpected keyword argument 'axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ht/74j_l0hj2lzg0r9j2xgjmd3r0000gn/T/ipykernel_40718/2436735597.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/m1tf/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: mean_squared_error() got an unexpected keyword argument 'axis'"
     ]
    }
   ],
   "source": [
    "tf.keras.metrics.mean_squared_error(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "75e02a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method MyLength.call of <__main__.MyLength object at 0x11b5f29d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method MyLength.call of <__main__.MyLength object at 0x11b5f29d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"model_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_52 (InputLayer)        [(None, None, 3)]         0         \n",
      "_________________________________________________________________\n",
      "my_length_47 (MyLength)      ((None, None, 3), ())     0         \n",
      "_________________________________________________________________\n",
      "lstm_80 (LSTM)               (None, 16)                1280      \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "reshape_19 (Reshape)         (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "my_repeat_31 (MyRepeat)      (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "lstm_81 (LSTM)               (None, None, 3)           240       \n",
      "=================================================================\n",
      "Total params: 1,602\n",
      "Trainable params: 1,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x11dff3820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x11dff3820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0045\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9870\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9711\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9568\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.9439\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.9318\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9200\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9080\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.8957\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x11e6ed760>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return 2\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return np.ones((128,40,3)), np.ones((128,40,3))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "\n",
    "class MyLength(Layer):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyLength, self).__init__(*args, **kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        s = tf.shape(inputs)[1]\n",
    "        \n",
    "        return inputs, s\n",
    "    \n",
    "class MyRepeat(Layer):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MyRepeat, self).__init__(*args, **kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x, s = inputs\n",
    "        \n",
    "        x = tf.repeat(x, s, axis=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "inp = keras.Input((None, 3))\n",
    "\n",
    "x, s = MyLength()(inp)\n",
    "x = keras.layers.LSTM(16)(x)\n",
    "x = keras.layers.Dense(2)(x)\n",
    "\n",
    "x = keras.layers.Dense(16)(x)\n",
    "x = keras.layers.Reshape((1, 16))(x)\n",
    "x = MyRepeat()([x,4])\n",
    "#x = keras.layers.RepeatVector(40)(x)\n",
    "out = keras.layers.LSTM(3, return_sequences=True)(x)\n",
    "\n",
    "model = keras.Model(inputs=inp, outputs=out)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "dg = DataGenerator()\n",
    "                                           \n",
    "                                           \n",
    "\n",
    "model.fit(x=dg, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4ed891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
