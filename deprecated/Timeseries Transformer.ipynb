{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eab421c",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "\n",
    "Ãœberwachte Implementierung der Transformer Architektur als Klassifkator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43be8f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import scipy.ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b9236f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the working directory of the ipykernel\n",
    "working_dir = os.getcwd()\n",
    "\n",
    "# define subdirectories\n",
    "data_path = os.path.join(working_dir, \"data\")\n",
    "xy_path = os.path.join(data_path, \"energy_robot_l400_s2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3298bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0,1,2,3,4]\n",
    "training_data_ratio = 80 # percent\n",
    "\n",
    "x = np.load(os.path.join(xy_path, \"x.npy\"))\n",
    "sequence_length = x.shape[1]\n",
    "num_features = x.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea7b382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aursad(classes=classes):\n",
    "    \n",
    "    x = np.load(os.path.join(xy_path, \"x.npy\"))\n",
    "    y = np.load(os.path.join(xy_path, \"y.npy\"))\n",
    "    sample_nr = np.load(os.path.join(xy_path, \"sample_nr.npy\"))\n",
    "    \n",
    "    # extract the relevant classes only\n",
    "    mask = [i in classes for i in y]\n",
    "    x = x[mask,:,:]\n",
    "    y = y[mask]\n",
    "    \n",
    "    # split dataset into training and test data\n",
    "    split = len(y) * training_data_ratio // 100\n",
    "  \n",
    "    rng = np.random.default_rng(0)\n",
    "    \n",
    "    idx = np.arange(len(y))\n",
    "    rng.shuffle(idx)\n",
    "    \n",
    "    train_idx = idx[:split]\n",
    "    test_idx = idx[split:]\n",
    "    \n",
    "    x_train = x[train_idx,::]\n",
    "    x_test = x[test_idx,::]\n",
    "    y_train = y[train_idx]\n",
    "    y_test = y[test_idx]\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "def split_dataset(x,y):\n",
    "    split = len(y)*7//10\n",
    "    \n",
    "    rng = np.random.default_rng(0)\n",
    "    \n",
    "    idx = np.arange(len(y))\n",
    "    rng.shuffle(idx)\n",
    "    \n",
    "    train_idx = idx[:split]\n",
    "    test_idx = idx[split:]\n",
    "    \n",
    "    x_train = x[train_idx,::]\n",
    "    x_test = x[test_idx,::]\n",
    "    y_train = y[train_idx]\n",
    "    y_test = y[test_idx]\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "    \n",
    "(x_train, y_train), (x_test, y_test) = aursad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc37fcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#y_train\n",
    "\n",
    "plt.hist(y_train, density=True, alpha=0.5, bins=[0,1,2,3,4,5])\n",
    "plt.hist(y_test, density=True, alpha=0.5, bins=[0,1,2,3,4,5])\n",
    "\n",
    "sequence_length = x_train.shape[1]\n",
    "num_features= x_train.shape[2]\n",
    "\n",
    "print(sequence_length)\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa1d67d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 400, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_16 (LayerNo (None, 400, 1)       2           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_8 (MultiHe (None, 400, 1)       1793        layer_normalization_16[0][0]     \n",
      "                                                                 layer_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 400, 1)       0           multi_head_attention_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_16 (TFOpLa (None, 400, 1)       0           dropout_20[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_17 (LayerNo (None, 400, 1)       2           tf.__operators__.add_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 400, 2)       4           layer_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 400, 2)       0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 400, 1)       3           dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_17 (TFOpLa (None, 400, 1)       0           conv1d_17[0][0]                  \n",
      "                                                                 tf.__operators__.add_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_18 (LayerNo (None, 400, 1)       2           tf.__operators__.add_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_9 (MultiHe (None, 400, 1)       1793        layer_normalization_18[0][0]     \n",
      "                                                                 layer_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 400, 1)       0           multi_head_attention_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_18 (TFOpLa (None, 400, 1)       0           dropout_22[0][0]                 \n",
      "                                                                 tf.__operators__.add_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_19 (LayerNo (None, 400, 1)       2           tf.__operators__.add_18[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 400, 2)       4           layer_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 400, 2)       0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 400, 1)       3           dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_19 (TFOpLa (None, 400, 1)       0           conv1d_19[0][0]                  \n",
      "                                                                 tf.__operators__.add_18[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 400)          0           tf.__operators__.add_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           12832       global_average_pooling1d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 32)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 8)            264         dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 8)            0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            9           dropout_25[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 16,713\n",
      "Trainable params: 16,713\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_classes=1\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    # Normalization and Attention\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(x, x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    return x + res\n",
    "\n",
    "def build_model(\n",
    "    input_shape,\n",
    "    head_size,\n",
    "    num_heads,\n",
    "    ff_dim,\n",
    "    num_transformer_blocks,\n",
    "    mlp_units,\n",
    "    dropout=0,\n",
    "    mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "    \n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=128,\n",
    "    num_heads=2,\n",
    "    ff_dim=2,\n",
    "    num_transformer_blocks=2,\n",
    "    mlp_units=[32,8],\n",
    "    #mlp_dropout=0.4,\n",
    "    #dropout=0.25,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",#\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(),#,learning_rate=1e-4),\n",
    "    metrics=\"accuracy\"\n",
    "    #metrics=\"categorical_cross_entropy\",#[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edb74f07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalies: 124.0\n",
      "Total: 408\n",
      "(1632, 400, 1)\n",
      "(1632,)\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x178f3a820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x178f3a820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "10/26 [==========>...................] - ETA: 24s - loss: 0.0000e+00 - accuracy: 0.3093"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ht/74j_l0hj2lzg0r9j2xgjmd3r0000gn/T/ipykernel_51152/3902860237.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, validation_data=(x_test, y_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#p = baseline.predict(x_train).reshape(-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/m1tf/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/m1tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/m1tf/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/m1tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/m1tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniforge3/envs/m1tf/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/m1tf/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_train_categorical = tf.keras.utils.to_categorical(y_train, num_classes=5)\n",
    "y_test_categorical = tf.keras.utils.to_categorical(y_test, num_classes=5)\n",
    "\n",
    "y_train[y_train != 0] = 1\n",
    "y_test[y_test != 0] = 1\n",
    "\n",
    "print(f\"Anomalies: {np.sum(y_test)}\")\n",
    "print(f\"Total: {len(y_test)}\")\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1, batch_size=64)#, validation_data=(x_test, y_test))\n",
    "\n",
    "#p = baseline.predict(x_train).reshape(-1)\n",
    "#p = p > 0.5\n",
    "#print(np.sum(p==y_train)/len(p))\n",
    "\n",
    "#baseline_classifier.fit(x_train, y_train_categorical, epochs=50, batch_size=64, validation_data=(x_test, y_test_categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9f8deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model():\n",
    "    \n",
    "    (_,_), (xtest, ytest)  = aursad()\n",
    "    \n",
    "    #mask = None\n",
    "    #if anomaly == None:\n",
    "    #    mask = np.ones((len(y_test,)), dtype=bool)\n",
    "    #else:\n",
    "    #    mask = np.logical_or(y_test==7, y_test==anomaly)\n",
    "    \n",
    "    #x_test = x_test[mask,::]\n",
    "    #y_test = y_test[mask]\n",
    "    \n",
    "    ytest[ytest!= 0] = 1\n",
    "    actual = ytest\n",
    "    \n",
    "    assert np.all(ytest == y_test)\n",
    "    \n",
    "    predicted = baseline.predict(xtest).reshape(-1)\n",
    "    predicted = predicted > 0.5\n",
    "    \n",
    "    # positiv = anomalous, negative = normal\n",
    "    tp = np.sum(np.logical_and(actual == 1, predicted == 1))\n",
    "    tn = np.sum(np.logical_and(actual == 0, predicted == 0))\n",
    "    fp = np.sum(np.logical_and(actual == 0, predicted == 1))\n",
    "    fn = np.sum(np.logical_and(actual == 1, predicted == 0))\n",
    "    n = len(ytest)\n",
    "    \n",
    "    print(f'TP = {tp}, TN = {tn}, FP = {fp}, FN = {fn}, N = {n}')\n",
    "    \n",
    "    accuracy = (tp+tn) / n\n",
    "    precision = tp / (tp+fp)\n",
    "    recall = tp / (tp+fn)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    print(f'Accuracy = {accuracy}, F1 = {f1}, precision = {precision}, recall = {recall}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d67761f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 89, TN = 263, FP = 21, FN = 35, N = 408\n",
      "Accuracy = 0.8627450980392157, F1 = 0.7606837606837606, precision = 0.8090909090909091, recall = 0.717741935483871\n"
     ]
    }
   ],
   "source": [
    "evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06940326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 3ms/step - loss: 0.7785 - binary_accuracy: 0.6023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.7784783840179443, 'binary_accuracy': 0.6023284196853638}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline.evaluate(x_train, y_train, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9b06e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline.save_weights(\"1DCNN-LSTM_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb34a701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 198, 16)           176       \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 198, 32)           6272      \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,313\n",
      "Trainable params: 15,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m2 = keras.models.load_model(\"1DCNN-LSTM.h5\")\n",
    "m2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a22360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
